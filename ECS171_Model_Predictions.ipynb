{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare input and target data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(filename, column):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tdf = read_csv(filename)\n",
    "\t# split into input (X) and output (y) variables & convert to numPy array\n",
    "\tX = df.drop(column, axis = 1).values\n",
    "\ty = df[column].values\n",
    "\treturn X, y\n",
    "\n",
    "# prepare input data\n",
    "def prepare_inputs(X_train, X_test):\n",
    "\toe = OrdinalEncoder()\n",
    "\toe.fit(X_train)\n",
    "\tX_train_enc = oe.transform(X_train)\n",
    "\tX_test_enc = oe.transform(X_test)\n",
    "\t\t\n",
    "\t# scale dataset\n",
    "\tscaler = preprocessing.MinMaxScaler()\n",
    "\tX_train_rescaled = scaler.fit_transform(X_train_enc)\n",
    "\tX_test_rescaled = scaler.fit_transform(X_test_enc)\n",
    "\treturn X_train_rescaled, X_test_rescaled\n",
    "\n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_dataset('mushrooms.csv', 'class')\n",
    "# split into train and test sets; 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute Logistic Regression and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of selected features:  10 \n",
      "\n",
      "Accuracy using ALL features: 94.77\n",
      "Accuracy using Chi2: 93.35\n",
      "Accuracy using Mutual Information: 90.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define how many features to select\n",
    "number_of_features = 10\n",
    "print('number of selected features: ', number_of_features, '\\n')\n",
    "\n",
    "# Feature reduction function\n",
    "def select_features(X_train, y_train, X_test, reduction_func):\n",
    " fs = SelectKBest(score_func=reduction_func, k=number_of_features)\n",
    " fs.fit(X_train, y_train)\n",
    " X_train_fs = fs.transform(X_train)\n",
    " X_test_fs = fs.transform(X_test)\n",
    " return X_train_fs, X_test_fs\n",
    "\n",
    "#### FEATURE SELECTION ####\n",
    "\n",
    "# chi2 feature selection\n",
    "X_train_fs_chi2, X_test_fs_chi2 = select_features(X_train_enc, y_train_enc, X_test_enc, chi2)\n",
    "\n",
    "# mutual information feature selection\n",
    "X_train_fs_mi, X_test_fs_mi = select_features(X_train_enc, y_train_enc, X_test_enc, mutual_info_classif)\n",
    "\n",
    "#### MODEL FITTING ####\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# all features\n",
    "model.fit(X_train_enc, y_train_enc)\n",
    "yhat = model.predict(X_test_enc)\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy using ALL features: %.2f' % (accuracy*100))\n",
    "\n",
    "# Chi2 features\n",
    "model.fit(X_train_fs_chi2, y_train_enc)\n",
    "yhat = model.predict(X_test_fs_chi2)\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy using Chi2: %.2f' % (accuracy*100))\n",
    "\n",
    "# Mutual Information featuresW\n",
    "model.fit(X_train_fs_mi, y_train_enc)\n",
    "yhat = model.predict(X_test_fs_mi)\n",
    "accuracy = accuracy_score(y_test_enc, yhat)\n",
    "print('Accuracy using Mutual Information: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Compute accuracy of Neural Network using Chi Squared Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a1. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'hidden_layer_sizes': (5, 7), 'learning_rate_init': 0.15, 'max_iter': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define how many features to select\n",
    "number_of_features = 10\n",
    "\n",
    "# feature selection\n",
    "def select_features_chi2(X_train, y_train, X_test):\n",
    " fs = SelectKBest(score_func=chi2, k=number_of_features)\n",
    " fs.fit(X_train, y_train)\n",
    " X_train_fs = fs.transform(X_train)\n",
    " X_test_fs = fs.transform(X_test)\n",
    " return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features_chi2(X_train_enc, y_train_enc, X_test_enc)\n",
    "# what are scores for the features\n",
    "#for i in range(len(fs.scores_)):\n",
    "# print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# Performing some hyperparameter tuning (it can take aorund 3 minutes)\n",
    "max_iterations = [500,800,1000]\n",
    "hidden_layer_siz = [(5, 7), (7, 13), (13, 10)]\n",
    "learning_rates = 0.15 * np.arange(1, 3)\n",
    "param_grid = dict(learning_rate_init = learning_rates, hidden_layer_sizes = hidden_layer_siz, max_iter = max_iterations)\n",
    "\n",
    "#set model\n",
    "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.3, batch_size = 100, hidden_layer_sizes = (12, 3), max_iter = 500)\n",
    "\n",
    "# For Grid Search\n",
    "grid = GridSearchCV(estimator = mlp, param_grid = param_grid)\n",
    "\n",
    "# Train the model with grid search\n",
    "grid_result = grid.fit(X_train_fs, y_train_enc)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a2. Fitting the model with the tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\~SCHOOL\\ecs171\\PROJECT\\ecs171-project\\ECS171_Model_Predictions.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/~SCHOOL/ecs171/PROJECT/ecs171-project/ECS171_Model_Predictions.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mlp\u001b[39m.\u001b[39mfit(X_train_enc, y_train_enc)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/~SCHOOL/ecs171/PROJECT/ecs171-project/ECS171_Model_Predictions.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m mlp\u001b[39m.\u001b[39mpredict(X_test_enc)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/~SCHOOL/ecs171/PROJECT/ecs171-project/ECS171_Model_Predictions.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test_enc, pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/~SCHOOL/ecs171/PROJECT/ecs171-project/ECS171_Model_Predictions.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (accuracy\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/~SCHOOL/ecs171/PROJECT/ecs171-project/ECS171_Model_Predictions.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Report : \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "#set model with the best hyperparameters that we just computed\n",
    "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = grid_result.best_params_[\"learning_rate_init\"], batch_size = 100, hidden_layer_sizes = grid_result.best_params_[\"hidden_layer_sizes\"], max_iter = grid_result.best_params_[\"max_iter\"])\n",
    "\n",
    "mlp.fit(X_train_fs, y_train_enc)\n",
    "mlp.predict(X_test_fs)\n",
    "\n",
    "accuracy = accuracy_score(y_test_enc, pred)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(y_test_enc, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a3. k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "[0.01226994 0.02453988 0.04294479 0.00613497 0.01226994 0.\n",
      " 0.00617284 0.         0.00617284 0.01234568]\n",
      "Average MSE =  0.012285086722714536\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn function cross_validate()\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "CV = cross_validate(mlp, X_test_fs, y_test_enc, cv=10, scoring=['accuracy', 'neg_mean_squared_error'])\n",
    "\n",
    "print('MSE')\n",
    "print(-1*CV['test_neg_mean_squared_error'])\n",
    "print('Average MSE = ', sum(-1 * CV['test_neg_mean_squared_error']) / len(CV['test_neg_mean_squared_error']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
